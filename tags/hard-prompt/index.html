<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Tag: hard prompt - SAIのBlog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="SAIのBlog"><meta name="msapplication-TileImage" content="C:\Users\11283\Pictures\icon\011-warning.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="SAIのBlog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="SAIのBlog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="SAIのBlog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="SAI_MUD"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"SAIのBlog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"SAI_MUD"},"publisher":{"@type":"Organization","name":"SAIのBlog","logo":{"@type":"ImageObject","url":{"text":"SAI"}}},"description":""}</script><link rel="icon" href="C:\Users\11283\Pictures\icon\011-warning.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">SAI</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/fatecantkillme"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags/">Tags</a></li><li class="is-active"><a href="#" aria-current="page">hard prompt</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2025-05-24T11:56:35.000Z" title="2025/5/24 19:56:35">2025-05-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2025-06-28T10:14:38.002Z" title="2025/6/28 18:14:38">2025-06-28</time></span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">29 minutes read (About 4396 words)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2025/05/24/NLP3/">SELF-INSTRUCT Aligning Language Models with Self-Generated Instructions</a></p><div class="content"><span id="more"></span>

<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>通过模型自己生成指令、输入输出，然后在使用它们对原始模型进行微调之前，过滤掉无效或相似的样本。</p>
<p><strong>SELF-INSTRUCT</strong>：一个通过利用预训练语言模型自身生成内容来提升其指令遵循能力的框架。</p>
<p>整理了一组专家编写的用于新颖任务的指令，并通过人工评估表明，使用 SELF-INSTRUCT 对 GPT3 进行调优，相比使用现有的公共指令数据集，性能有大幅提升，与 InstructGPT001 仅存在 5% 的绝对差距。</p>
<blockquote>
<p>指令调优模型：用 指令-输入-输出 做监督学习的微调模型</p>
</blockquote>
<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p><strong>指令遵循模型</strong>成功的两大支柱：模型本身（强大的预训练语言模型）和高质量的训练数据（<strong>人工编写</strong>的指令数据）</p>
<p><strong>问题：</strong></p>
<ol>
<li>成本高昂</li>
<li>多样性有限，人写的一般只会包含常见的NLP任务如翻译、总结</li>
</ol>
<p><strong>SELF-INSTRUCT：</strong></p>
<p><img src="https://img.picui.cn/free/2025/05/24/68317db324338.png" alt="QQ截图20250524160501.png"></p>
<ul>
<li>在第一阶段，模型被提示（prompted）生成新任务的指令。<strong>利用现有的指令集合来创建覆盖范围更广的指令</strong>，这些指令定义了（通常是新颖的）任务。</li>
<li>第二阶段，判断指令对应的任务是否为分类任务</li>
<li>第三阶段，如果是分类任务类型则先生成输出再生成输入否则先生成输入后生成输出</li>
<li>第四阶段，过滤掉重复和无用的</li>
</ul>
<p>经过循环自举，self-instruct机制生成了种类非常丰富的instruction：</p>
<p><img src="https://img.picui.cn/free/2025/05/25/68331536b761b.png" alt="QQ截图20250525210345.png"></p>
<p>基于这些生成的数据，我们通过对 GPT3（即用于生成指令数据的同一个模型）进行微调，构建了 GPT3SELF-INST 模型。结果表明，GPT3SELF-INST 以显著优势（+33.1%）超越了原始的 GPT3 模型，并且几乎与 InstructGPT001 的性能持平。</p>
<p>贡献包括：</p>
<p>(1) 我们<strong>引入了 SELF-INSTRUCT</strong>，一种以最少人工标注数据诱导（提升）指令遵循能力的方法；</p>
<p>(2) 我们通过<strong>广泛的指令调优实验</strong>证明了其有效性；</p>
<p>(3) 我们发布了一个包含 52,000 条指令的<strong>大型合成数据集</strong>，以及一组用于构建和评估未来指令遵循模型的人工编写的新颖任务。</p>
<h2 id="method"><a href="#method" class="headerlink" title="method"></a>method</h2><h3 id="Defining-Instruction-Data"><a href="#Defining-Instruction-Data" class="headerlink" title="Defining Instruction Data"></a>Defining Instruction Data</h3><p>生成的指令数据包含一个指令集合 I_t，其中每个 I_t 都以自然语言定义了一个任务 t,每个任务t包含≥1个输入输出实例。</p>
<p>由于很多时候指令和输出不存在明显界限，比如一个写作任务既可以表示为：“写一篇关于校园安全的文章”，也可以表示为：“写一篇关于以下主题的文章”，并将“校园安全”作为实例输入。</p>
<p>为了提升模型鲁棒性，允许无输入的指令</p>
<h3 id="Automatic-Instruction-Data-Generation"><a href="#Automatic-Instruction-Data-Generation" class="headerlink" title="Automatic Instruction Data Generation"></a>Automatic Instruction Data Generation</h3><p>数据生成流水线包含四个步骤：1) 生成任务指令，2) 判断指令是否代表一个分类任务，3) 使用输入优先或输出优先的方法生成实例，以及 4) 过滤低质量数据。</p>
<ul>
<li>**在第一步，**SELF-INSTRUCT 以自举（bootstrapping）方式，从一小组人工编写的种子指令中生成新的指令我们用 175 个任务来初始化任务池（每个任务包含 1 条指令和 1 个实例）在每一步中，我们从这个任务池中抽取 8 条任务指令作为上下文示例这 8 条指令中，有 6 条来自人工编写的任务，有 2 条来自之前步骤中模型生成的任务，以促进多样性。</li>
</ul>
<p><img src="https://img.picui.cn/free/2025/05/25/68332af6cbbbc.png" alt="QQ截图20250525223631.png"></p>
<ul>
<li><strong>分类任务识别</strong>：以<strong>少样本（few-shot</strong>）方式提示语言模型来判断这一点，使用了来自种子任务的 12 条分类指令和 19 条非分类指令。</li>
</ul>
<p><img src="/./NLP3.assets/image-20250525223933360.png" alt="image-20250525223933360"></p>
<ul>
<li><p><strong>Instance Generation</strong>：当使用来自其他任务的“指令-输入-输出”上下文示例进行提示时，预训练语言模型在很大程度上能够做到根据指令理解目标任务是什么，找出需要哪些额外的输入字段并生成它们，最后通过生成输出来完成任务。</p>
</li>
<li><ul>
<li>input-first：先生成输入再生成输出的策略。<strong>这种方法可能会生成偏向于某个特定标签的输入，特别是对于分类任务（例如，对于语法错误检测任务，它通常会生成语法正确的输入）</strong>。<img src="https://img.picui.cn/free/2025/05/25/68332d35c33d3.png" alt="QQ截图20250525224544.png"></li>
<li>Output-first Approach：首先生成可能的类别标签，然后根据每个类别标签生成输入<img src="https://img.picui.cn/free/2025/05/25/68332d35d054a.png" alt="QQ截图20250525224600.png"></li>
</ul>
</li>
<li><p><strong>Filtering and Postprocessing：<strong>为了鼓励多样性，<strong>一条新的指令只有当其与任何现有指令的 ROUGE-L 相似度小于 0.7 时才会被添加到任务池中</strong>。还</strong>排除了那些包含某些特定关键词</strong>（例如 image、picture、graph）的指令，因为这些指令通常无法由语言模型处理。在为每条指令生成新的实例时，我们会<strong>过滤掉完全相同的实例，或者输入相同但输出不同的实例</strong>。无效的生成内容会根据启发式方法进行识别和过滤（例如，<strong>指令过长或过短，实例输出是输入的重复</strong>）。</p>
</li>
</ul>
<h3 id="Finetuning-the-LM-to-Follow-Instructions"><a href="#Finetuning-the-LM-to-Follow-Instructions" class="headerlink" title="Finetuning the LM to Follow Instructions"></a>Finetuning the LM to Follow Instructions</h3><p>我们<strong>将指令和实例输入连接起来作为提示（prompt）</strong>，并以标准的监督学习方式训练模型生成实例输出。为了使模型对不同格式具有鲁棒性，我们<strong>使用多个模板将指令和实例输入编码在一起</strong>。例如，指令可以带或不带前缀“Task:”，输入可以带或不带前缀“Input:”，“Output:”可以加或不加在提示的末尾，并且中间可以放置不同数量的换行符等</p>
<h2 id="SELF-INSTRUCT-Data-from-GPT3"><a href="#SELF-INSTRUCT-Data-from-GPT3" class="headerlink" title="SELF-INSTRUCT Data from GPT3"></a>SELF-INSTRUCT Data from GPT3</h2><p>接下来对GPT3生成的instruct数据集做分析</p>
<h3 id="statistics"><a href="#statistics" class="headerlink" title="statistics"></a>statistics</h3><p><img src="https://img.picui.cn/free/2025/05/25/68332fb8a9c9f.png" alt="QQ截图20250525225656.png"></p>
<h3 id="Diversity"><a href="#Diversity" class="headerlink" title="Diversity"></a>Diversity</h3><p>使用 Berkeley 神经网络解析器提取最接近根节点的动词及其第一个直接名词宾语</p>
<p><img src="https://img.picui.cn/free/2025/05/26/6833ddd26ba20.png" alt="QQ截图20250526111947.png"></p>
<p><img src="https://img.picui.cn/free/2025/05/26/6833de0e37a83.png" alt="QQ截图20250526112017.png"></p>
<p><img src="https://img.picui.cn/free/2025/05/26/6833de0e23b12.png" alt="QQ截图20250526112022.png"></p>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><h3 id="GPT3SELF-INST-finetuning-GPT3-on-its-own-instruction-data"><a href="#GPT3SELF-INST-finetuning-GPT3-on-its-own-instruction-data" class="headerlink" title="GPT3SELF-INST: finetuning GPT3 on its own instruction data"></a>GPT3SELF-INST: finetuning GPT3 on its own instruction data</h3><p>使用多种模板来连接指令和输入，并训练模型生成输出</p>
<p>这种微调是通过 OpenAI 微调 API 完成的</p>
<p>对模型进行了 2 个epochs的训练</p>
<h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><ul>
<li><p>Off-the-shelf LMs ：T5-LM 、 GPT3 </p>
</li>
<li><p>Publicly available instruction-tuned models： **T0 ：**Hugging Face 团队开发的指令调优模型，基于 T5 架构，通过在多个自然语言任务的指令数据上进行微调而得到。<strong>Tk-INSTRUCT (Wang et al., 2022):</strong> 另一个指令调优模型，通常指 SUPERNI (SUPER-NATURALINSTRUCTIONS) 数据集上训练的模型，旨在提升模型在各种任务上的泛化能力。</p>
</li>
<li><p>Instruction-tuned GPT3 models： InstructGPT</p>
</li>
</ul>
<p>为了将 SELF-INSTRUCT 训练与使用其他公开可用的指令调优数据进行比较，我们进一步使用来自PROMPTSOURCE 和 SUPERNI 的数据对 GPT3 模型进行了微调，这些数据曾用于训练 T0 和 Tk-INSTRUCT 模型。</p>
<p>T0 training and SUPERNI training</p>
<h3 id="Experiment-1-Zero-Shot-Generalization-on-SUPERNI-benchmark"><a href="#Experiment-1-Zero-Shot-Generalization-on-SUPERNI-benchmark" class="headerlink" title="Experiment 1: Zero-Shot Generalization on SUPERNI benchmark"></a>Experiment 1: Zero-Shot Generalization on SUPERNI benchmark</h3><p>以<strong>零样本（zero-shot</strong>）的方式，评估模型在典型自然语言处理（NLP）任务上遵循指令的能力。</p>
<p>使用 SUPERNI (Wang 等，2022) 的评估集</p>
<p>使用确定性生成模式（温度设置为 0，不进行核采样），并且没有使用特定的停止序列。</p>
<p><img src="https://img.picui.cn/free/2025/05/26/6833e56b4bc64.png" alt="QQ截图20250526115208.png"></p>
<ol>
<li><p>SELF-INSTRUCT 能够大幅提升 GPT3 的性能（+33.1%）</p>
</li>
<li><p>几乎与 InstructGPT001 的性能持平。</p>
</li>
<li><p>即使在已有大量标注指令数据的情况下，它也能进一步提升性能</p>
</li>
</ol>
<p>原始的 GPT3 模型基本上完全无法遵循人类指令。经人工分析，我们发现它通常生成不相关且重复的文本，并且不知道何时停止生成</p>
<p>与其他未专门针对 SUPERNI 进行训练的模型相比，GPT3SELF-INST 取得了比 T0 模型或在 T0 训练集上微调的 GPT3 模型更好的性能，而 T0 训练集付出了巨大的人工标注努力。</p>
<p>值得注意的是，GPT3SELF-INST 还几乎与 InstructGPT001 的性能持平，而 InstructGPT001 是使用私人用户数据和人工标注标签进行训练的。</p>
<h3 id="Experiment-2-Generalization-to-User-oriented-Instructions-on-Novel-Tasks"><a href="#Experiment-2-Generalization-to-User-oriented-Instructions-on-Novel-Tasks" class="headerlink" title="Experiment 2: Generalization to User-oriented Instructions on Novel Tasks"></a>Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</h3><p>尽管 SUPERNI 在收集现有 NLP 任务方面很全面，但这些 NLP 任务大多是为研究目的而提出，并且倾向于分类任务。</p>
<p>为了更好地评估指令遵循模型的实际价值，部分作者策划了一组受面向用户应用启发的新指令。</p>
<p>首先集思广益，思考大型语言模型可能有用处的各种领域（例如，电子邮件撰写、社交媒体、生产力工具、娱乐、编程），然后针对每个领域精心设计指令以及一个输入-输出实例（同样，输入是可选的）。</p>
<p>目标是使这些任务的风格和格式多样化（例如，指令可能长或短；输入&#x2F;输出可能采取列表、表格、代码、公式等形式）。</p>
<p>建了 252 条指令，每条指令包含 1 个实例。</p>
<p>相信它可以作为测试平台，用于评估基于指令的模型如何处理多样化和不熟悉的指令。</p>
<p>为了获得更忠实的评估，我们请指令的作者来判断模型的预测</p>
<p>实施了一个四级评分系统，用于对模型输出的质量进行分类：</p>
<ul>
<li>RATING-A：响应有效且令人满意。</li>
<li>RATING-B：响应可接受，但存在轻微错误或不完美之处。</li>
<li>RATING-C：响应相关且回应了指令，但内容存在重大错误。</li>
<li>RATING-D：响应不相关或完全无效</li>
</ul>
<p><img src="https://img.picui.cn/free/2025/05/26/6833ffa9964fb.png" alt="QQ截图20250526134410.png"></p>
<h3 id="Effect-of-Data-Size-and-Quality"><a href="#Effect-of-Data-Size-and-Quality" class="headerlink" title="Effect of Data Size and Quality"></a>Effect of Data Size and Quality</h3><p>更多这种生成的数据能否带来更好的指令遵循能力呢?</p>
<p>通过从生成的数据集中抽取不同数量的指令子集，用这些子集微调 GPT3，并评估由此得到的模型在 252 个面向用户的指令集上的表现，从而对生成数据的规模进行了分析</p>
<p><img src="https://img.picui.cn/free/2025/05/26/68340085334b6.png" alt="QQ截图20250526134745.png"></p>
<p>随着数据规模的增长，性能持续提升。然而，这种提升在达到 16,000 条指令后几乎趋于平稳。</p>
<p>有趣的是，当在 SUPERNI 上进行评估时，我们发现模型的性能提升在数百条指令左右就更早地趋于平稳。</p>
<p>这可能是由于新生成的数据与 SUPERNI 中典型的 NLP 任务有所不同，这表明未来的研究可能受益于结合使用不同的指令数据，以在各种类型的任务上获得更好的性能。</p>
<p>另一个提高模型性能的方向是利用我们生成的数据并获得更好的监督信号（减少噪声）。通过使用 InstructGPT003（当时可用的最佳通用模型），根据指令和输入重新生成我们所有实例的输出字段，从而探索了这一想法</p>
<p>这可以被视为使用我们的数据对 InstructGPT003 进行的一种知识蒸馏。</p>
<p>由此得到的模型比使用原始数据训练的对应模型性能高出 10%，这表明未来在利用我们的生成流水线获取初始数据，然后通过人类专家或从更优模型进行知识蒸馏来提高数据质量方面，有很大的研究空间。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Instruction-following-LMs"><a href="#Instruction-following-LMs" class="headerlink" title="Instruction-following LMs."></a>Instruction-following LMs.</h3><p>一系列工作已经发现证据表明，如果原始语言模型（LM）通过标注的“指令性”数据进行调优——这些数据集包含基于人工标注的语言指令命令及其预期结果——它们可以有效地遵循通用语言指令</p>
<p>“指令性”数据的规模和多样性与所得模型对未见任务的泛化能力之间存在直接关联</p>
<p>InstructGPT (Ouyang 等，2022) 在构建更通用目的的语言模型方面与我们的目标相似，并且在遵循多样化用户指令方面展示了卓越的性能。然而，作为一个商业系统，它们的构建过程仍然相当不透明。特别是，由于透明度有限以及他们在研究中使用的私人用户数据，数据在其中所扮演的角色仍未得到充分研究。</p>
<h3 id="Language-models-for-data-generation-and-augmentation"><a href="#Language-models-for-data-generation-and-augmentation" class="headerlink" title="Language models for data generation and augmentation"></a>Language models for data generation and augmentation</h3><p>SELF-INSTRUCT 的一个独特动机是自举（bootstrap）新的任务定义，这些任务以前可能从未被自然语言处理（NLP）从业者定义过（尽管对真实用户来说可能仍然很重要）</p>
<h3 id="Instruction-generation"><a href="#Instruction-generation" class="headerlink" title="Instruction generation"></a>Instruction generation</h3><p> 一系列近期工作（Zhou 等，2022b；Ye 等，2022；Singh 等，2022；Honovich 等，2022b）在给定少量示例的情况下生成任务的指令。尽管 SELF-INSTRUCT 也涉及指令生成，但我们案例中的一个主要区别在于它是<strong>任务无关</strong>的；我们从头开始生成新的任务（指令连同实例）。</p>
<h3 id="Model-self-training"><a href="#Model-self-training" class="headerlink" title="Model self-training"></a>Model self-training</h3><p>典型的自训练框架（He 等，2019；Xie 等，2020；Du 等，2021；Amini 等，2022；Huang 等，2022）使用训练好的模型为未标注数据分配标签，然后利用这些新标注的数据来改进模型。尽管 SELF-INSTRUCT 与自训练文献有相似之处，但大多数自训练方法都假设一个特定的目标任务以及其下的未标注示例；相比之下，SELF-INSTRUCT 则从头开始生成各种各样的任务。</p>
<h3 id="Knowledge-distillation"><a href="#Knowledge-distillation" class="headerlink" title="Knowledge distillation."></a>Knowledge distillation.</h3><p>SELF-INSTRUCT 也可以被视为一种“知识蒸馏”的形式，但它与此方向的不同之处在于：(1) 蒸馏的来源和目标是相同的，即模型的知识被蒸馏到它自身；(2) 蒸馏的内容是以指令任务的形式存在的（即定义任务的指令，以及实例化该任务的一组示例）。</p>
<h3 id="Bootstrapping-with-limited-resources"><a href="#Bootstrapping-with-limited-resources" class="headerlink" title="Bootstrapping with limited resources"></a>Bootstrapping with limited resources</h3><p>SELF-INSTRUCT 本身就是“有限资源下自举”的一个典型例子。它从<strong>少量人工编写的种子指令（有限资源）**开始，利用 **GPT3 模型自身的生成能力**，通过**迭代过程（自举）**，来生成</strong>大规模、多样化的指令数据**，最终用于微调模型，使其更好地遵循指令。</p>
<h3 id="Multi-modal-instruction-following"><a href="#Multi-modal-instruction-following" class="headerlink" title="Multi-modal instruction-following"></a>Multi-modal instruction-following</h3><p>SELF-INSTRUCT 作为一种通用的数据扩展方法，也有潜力在multi-modal learning发挥作用，我们将其留待未来的工作。</p>
<h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><p><strong>Tail phenomena (长尾现象):</strong> 在许多现实世界分布中，少数高频事件构成“头部”，而大量低频事件构成“长尾”。在语言模型中，这通常指模型在处理高频词汇和常见语言模式时表现良好，但在处理低频词汇、不常见表达或特定领域（即“长尾”）时性能下降。</p>
<p>类似地，在本文的背景下，如果 SELF-INSTRUCT 的大部分收益偏向于在预训练语料库中出现频率更高的任务或指令，那将不足为奇。</p>
<p>因此，这种方法在面对不常见和富有创造性的指令时可能会表现出脆弱性。</p>
<p>对于更大的模型，指令调优的收益更高（Wei 等，2022）。这可能会给那些没有大型计算资源的人造成使用障碍</p>
<p><strong>强化语言模型偏见。</strong> 作者关注的一个问题是这种迭代算法可能带来的意外后果，例如问题性社会偏见（关于性别、种族等的刻板印象或污蔑言论）的放大。</p>
<p>该算法难以生成平衡的标签，这反映了模型先前的偏见。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://www.gravatar.com/avatar/96bd83aac6004b898e6081975c10f344?s=128" alt="SAI_MUD"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">SAI_MUD</p><p class="is-size-6 is-block">无名小卒</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Chengdu</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives/"><p class="title">18</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories/"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags/"><p class="title">29</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/fatecantkillme" target="_blank" rel="me noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/fatecantkillme"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Weibo" href="https://m.weibo.cn/profile/7024554023"><i class="fab fa-weibo"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/DL/"><span class="level-start"><span class="level-item">DL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%93%B2%E5%AD%A6/"><span class="level-start"><span class="level-item">哲学</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BF%83%E7%90%86%E5%AD%A6/"><span class="level-start"><span class="level-item">心理学</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"><span class="level-start"><span class="level-item">数学建模</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"><span class="level-start"><span class="level-item">碎碎念</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A4%BE%E4%BC%9A%E5%AD%A6/"><span class="level-start"><span class="level-item">社会学</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%B2%BE%E7%A5%9E%E5%88%86%E6%9E%90/"><span class="level-start"><span class="level-item">精神分析</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%BB%8F%E6%B5%8E/"><span class="level-start"><span class="level-item">经济</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-06-28T09:54:24.000Z">2025-06-28</time></p><p class="title"><a href="/2025/06/28/ok/">ok</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-24T11:56:35.000Z">2025-05-24</time></p><p class="title"><a href="/2025/05/24/NLP3/">SELF-INSTRUCT Aligning Language Models with Self-Generated Instructions</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-20T12:32:00.000Z">2025-05-20</time></p><p class="title"><a href="/2025/05/20/%E6%8B%89%E5%BA%B7%E6%80%9D%E6%83%B3%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%8F%8A%E7%90%86%E8%AE%BA%E6%A8%A1%E5%9E%8B/">拉康思想的基本概念及理论模型</a></p><p class="categories"><a href="/categories/%E7%B2%BE%E7%A5%9E%E5%88%86%E6%9E%90/">精神分析</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-05-10T06:56:35.000Z">2025-05-10</time></p><p class="title"><a href="/2025/05/10/NLP1/">Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2025-04-25T02:58:07.000Z">2025-04-25</time></p><p class="title"><a href="/2025/04/25/pytorch&amp;DL/">pytorch&amp;DL tutorial (LiMu)</a></p><p class="categories"><a href="/categories/DL/">DL</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item">June 2025</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/05/"><span class="level-start"><span class="level-item">May 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/04/"><span class="level-start"><span class="level-item">April 2025</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/03/"><span class="level-start"><span class="level-item">March 2025</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP%E5%85%A5%E9%97%A8/"><span class="tag">NLP入门</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hard-prompt/"><span class="tag">hard prompt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/prompt-engine/"><span class="tag">prompt engine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%90%8E%E7%BB%93%E6%9E%84%E4%B8%BB%E4%B9%89/"><span class="tag">后结构主义</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%93%B2%E5%AD%A6/"><span class="tag">哲学</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7/"><span class="tag">弗洛伊德</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BD%93%E4%BB%A3%E6%96%87%E5%AD%A6/"><span class="tag">当代文学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BD%93%E4%BB%A3%E8%89%BA%E6%9C%AF/"><span class="tag">当代艺术</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"><span class="tag">心理学</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8B%89%E5%BA%B7/"><span class="tag">拉康</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"><span class="tag">数学建模</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"><span class="tag">数据处理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%A8%A1/"><span class="tag">数模</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B3%95%E5%85%B0%E5%85%8B%E7%A6%8F%E5%AD%A6%E6%B4%BE/"><span class="tag">法兰克福学派</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%95%85%E9%94%80%E4%B9%A6/"><span class="tag">畅销书</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A4%BE%E4%BC%9A%E5%AD%A6/"><span class="tag">社会学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B2%BE%E7%A5%9E%E5%88%86%E6%9E%90/"><span class="tag">精神分析</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E6%B5%8E/"><span class="tag">经济</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9D%E5%AF%B9%E5%94%AF%E5%BF%83%E4%B8%BB%E4%B9%89/"><span class="tag">绝对唯心主义</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E7%BB%9C%E6%9D%82%E8%B0%88/"><span class="tag">网络杂谈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%8D%A3%E6%A0%BC/"><span class="tag">荣格</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95/"><span class="tag">评价方法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9B%86%E4%BD%93%E6%BD%9C%E6%84%8F%E8%AF%86/"><span class="tag">集体潜意识</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%BB%91%E6%A0%BC%E5%B0%94/"><span class="tag">黑格尔</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">SAI</a><p class="is-size-7"><span>&copy; 2025 SAI_MUD</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2025</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script data-pjax src="/js/insight.js" defer></script><script data-pjax>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>